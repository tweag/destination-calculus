% -*- latex -*-
\documentclass[acmsmall, screen]{acmart}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsthm}
\let\Bbbk\relax % needed because of a conflict between amssymb and newtx
\usepackage{amssymb}
\usepackage{subcaption}

% For OTT rendering
\usepackage[supertabular]{ottalt}
\inputott{destination_calculus_ott.tex}
\usepackage{ottstyling}
% Hide "Index for ranges" from the metavars displayed tabular
\patchcmd{\ottmetavars}{$ \ottmv{k} $ & \ottcom{Index for ranges} \\}{}{}{}

% \setlength\textfloatsep{\baselineskip}
% \setlength{\intextsep}{\baselineskip}

\newcommand{\TODO}[1]{~\textnormal{\textcolor{red}{TODO: #1} } }
\newcommand\sepimp{\mathrel{-\mkern-6mu*}}
\newcommand{\parr}{\rotatebox[origin=c]{180}{\&}}
\makeatletter
\newcommand{\smallbullet}{} % for safety
\DeclareRobustCommand\smallbullet{%
  \mathord{\mathpalette\smallbullet@{0.5}}%
}
\newcommand{\smallbullet@}[2]{%
  \vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}%
}
\makeatother

\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TITLE SECTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\acmJournal{PACMPL}
\acmConference[POPL'25]{Principles of Programming Languages}{January 19 -- 25, 2025}{Denver, Colorado}
\title{Destination calculus}
\subtitle{A linear $\lambda-$calculus for pure, functional memory updates}

\author{Arnaud Spiwack}
\orcid{0TBD-0TBD-0TBD-0TBD}
\affiliation{
  \institution{Modus Create}
  \department{TWEAG - OSPO}
  \position{Director of Research}
  \city{Paris}
  \country{France}
}
\email{arnaud.spiwack@tweag.io}

\author{Thomas Bagrel}
\orcid{0009-0008-8700-2741}
\affiliation{
  \institution{LORIA/Inria}
  \department{MOSEL VERIDIS}
  \city{Nancy}
  \country{France}
}
\affiliation{
  \institution{Modus Create}
  \department{TWEAG - OSPO}
  \city{Paris}
  \country{France}
}
\email{thomas.bagrel@loria.fr}
\email{thomas.bagrel@tweag.io}

\begin{abstract}
  We present the destination calculus, a linear $\lambda-$calculus for
  pure, functional memory updates. We introduce the
  syntax, type system, and operational semantics of the destination
  calculus, and prove type safety formally in the Coq proof assistant.
  
  We show how the principles of the destination calculus can form a theoretical ground
  for destination-passing style programming in functional languages. In particular,
  we detail how the present work can be applied to Linear Haskell to lift the main 
  restriction of DPS programming in Haskell as developed in \cite{bagrel_destination-passing_2024}.
  We illustrate this with a range of pseudo-Haskell examples.
\end{abstract}

\maketitle

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\section{System in action on simple examples}

Build up to DList.

\section{Limitions of the previous approach}

\subsection{Breadth-first tree traversal}
\subsection{Storing linear data in destination-based data structures}
\subsection{Need for scope control}

\section{Updated breadth-first tree traversal}

\clearpage

\section{Language syntax}

\subsection{Introducing the \emph{ampar}}

Minamide's work\cite{minamide_functional_1998} is the earliest record we could find of a functional calculus integrating the idea of incomplete data structures (structures with holes) that exist as first class values and can be interacted with by the user.

In that paper, a structure with a hole is named \emph{hole abstraction}. In the body of a hole abstraction, the bound \emph{hole variable} should be used linearly (exactly once), and must only be used as a parameter of a data constructor. In other terms, the bound \emph{hole variable} cannot be pattern-matched on or used as a parameter of a function call. A hole abstraction is thus a weak form of linear lambda abstraction, which just moves a piece of data into a bigger data structure.

In fact, the type of hole abstraction $\ottstype{([[T1]], [[T2]]) hfun}$ in Minamine's work shares a lot of similarity with the separating implication or \emph{magic wand} $\ottstype{[[T1]] \sepimp [[T2]]}$ from separation logic: given a piece of memory matching description $[[T1]]$, we obtain a (complete) piece of memory matching description $[[T2]]$.

Now, in classical linear logic, we know we can transform linear implication $\ottstype{[[T1]] \multimap [[T2]]}$ into $\ottstype{[[T1]]^{\bot}~\parr~[[T2]]}$. Doing so for the \emph{wand} type $\ottstype{([[T1]], [[T2]]) hfun}$ or $\ottstype{[[T1]] \sepimp [[T2]]}$ gives $\ottstype{\lfloor[[T1]]\rfloor~ \widehat{\parr}~[[T2]]}$, where $\ottstype{\lfloor\smallbullet\rfloor}$ is memory negation, and $\ottstype{\widehat{\parr}}$ is a memory \emph{par} (weaker than the CLL \emph{par} that allows more ``interaction'' of its two sides).

Transforming the hole abstraction from its original implication form to a \emph{par} form let us consider the type $\ottstype{\lfloor[[T1]]\rfloor}$ of \emph{sink} or \emph{destination} of $[[T1]]$ as a first class component of our calculus. We also get to see the hole abstraction aka memory par as a pair-like structure, where the two sides might be coupled together in a way that prevent using both of them simultaneously.

\paragraph{From memory par $\ottstype{\widehat{\parr}}$ to ampar $\ottstype{\ltimes}$}

In CLL, the cut rule states that given $\ottstype{[[T1]]~\parr~[[T2]]}$, we can free up $[[T1]]$ by providing an eliminator of $[[T2]]$, or free up $[[T2]]$ by providing an eliminator of $[[T1]]$. The eliminator of $[[T]]$ can be $\ottstype{[[T]]^\bot}$, or $\ottstype{[[T]]^{\bot^{-1}}} = [[T']]$ if $[[T]]$ is already of the form $\ottstype{[[T']]^\bot}$. In a classical setting, thanks to the involutive nature of negation $\ottstype{\smallbullet^\bot}$, the two potential forms of the eliminator of $[[T]]$ are equal.

In destination calculus though, we don't have an involutive memory negation $\ottstype{\lfloor\smallbullet\rfloor}$. If we are provided with a destination of destination $[[-h']] : \ottstype{\lfloor\lfloor[[T]]\rfloor\rfloor}$, we know that some structure is expecting to store a destination of type $\ottstype{\lfloor[[T]]\rfloor}$. If ever that structure is consumed, then the destination stored inside will have to be filled with a value (remember we are in a linear calculus). So if we allocate a new memory slot of type $[[+h]] : [[T]]$ and its linked destination $[[-h]] : \ottstype{\lfloor[[T]]\rfloor}$, and write $[[-h]]$ to the memory slot pointed to by $[[-h']]$, then we can get back a value of type $[[T]]$ at $[[+h]]$ if ever the structure pointed to by $[[-h']]$ is consumed. Thus, a destination of destination is only equivalent to the promise of an eventual value, not an immediate usable one.

As a result, in destination calculus, we cannot have the same kind of cut rule as in CLL. This is, in fact, the part of destination calculus that was the hardest to design, and the source of a lot of early errors. For a destination of type $\ottstype{\lfloor[[T]]\rfloor}$, both storing it through a destination of destination $\ottstype{\lfloor\lfloor[[T]]\rfloor\rfloor}$ or using it to store a value of type $[[T]]$ constitute a linear use of the destination. But only the latter is a genuine consumption in the sense that it guarantees that the hole associated to the destination has been filled! Storing away the destination of type $\ottstype{\lfloor[[T]]\rfloor}$ in $\ottstype{[[T]]~\widehat{\parr}~\lfloor[[T]]\rfloor}$ (through a destination of destination of type $\ottstype{\lfloor\lfloor[[T]]\rfloor\rfloor}$) should not allow to free up the $[[T]]$, as it would in a CLL-like setting.

\subsection{Names and variables}

The destination calculus uses two classes of names: regular (meta) variable names $[[x]], [[y]]$, and hole names, $[[h]], [[h1]], [[h2]]$ which represents the identifier or address of a memory cell that hasn't been written to yet.

\ottmetavars
\ottgrammartabular{
\otthvar\ottafterlastrule
}

Hole names are represented by natural numbers under the hood, so they can act both as relative offsets or absolute positions in memory. Typically, when a structure is effectively allocated, its hole names are shifted by the maximum hole name encountered so far in the program ; this corresponds to finding the next unused memory cell in which to write new data.

We sometimes need to keep track of hole names bound by a particular runtime value or evaluation context, hence we also define sets of hole names $[[H]], [[H1]], [[H2]]\ldots$.

\ottgrammartabular{
\otthvars\ottafterlastrule
}

Shifting all hole names in a set by a given offset $[[h']]$ is denoted $[[H ⩲ h']]$. We also define a conditional shift operation $\ottshvar{[}[[H ⩲ h']]\ottshvar{]}$ which shifts each hole name appearing in the operand to the left of the brackets by $[[h']]$ if this hole name is also member of $[[H]]$. This conditional shift can be used on a single hole name, a value, or a typing context.

\subsection{Term and value core syntax}

Destination calculus is based on linear simply-typed $\lambda$-calculus, with built-in support for sums, pairs, and exponentials. The syntax of terms is quite unusual, as we need to introduce all the tooling required to manipulate destinations, which constitute the primitive way of building a data structures for the user.

In fact, the grammatical class of values $[[v]]$, presented as a subset of terms $[[t]]$, could almost be removed completely from the user syntax, and just used as a denotation for runtime data structures. We only need to keep the \emph{ampar} value $[[{ h } ⟨ +h ❟ -h ⟩]]$ as part of the user syntax as a way to spawn a fresh memory cell to be later filled using destination-filling primitives (see $[[alloc]]$ in Section~\ref{ssec:sugar}).

\ottgrammartabular{
\ottterm\ottinterrule
\ottval\ottafterlastrule
}

Pattern-matching on every type of structure (except unit) is parametrized by a mode $[[m]]$ to which the scrutinee is consumed. The variables which bind the subcomponents of the scrutinee then inherit this mode. In particular, this choice crystalize the equivalence $[[! ωa (T1 ⨂ T2)]] \simeq [[(! ωa T1) ⨂ (! ωa T2)]]$, which is not part of intuitionistic linear logic, but valid in Linear Haskell\cite{bernardy_linear_2018}.

$\ottkw{map}$ is the main primitive to operate on an \emph{ampar}, which represents an incomplete data structure whose building is in progress. $\ottkw{map}$ binds the right-hand side of the \emph{ampar} --- the one containing destinations of that \emph{ampar} --- to a variable, allowing those destinations to be operated on by destination-filling primitives. The left-hand side of the \emph{ampar} is inaccessible as it is being mutated behind the scenes by the destination-filling primitives.

$\ottkw{to}_{\ottstype{\ltimes}}$ embeds an already completed structure in an \emph{ampar} whose left side is the structure, and right side is unit. We have an operator \textsc{FillComp} ($\triangleleft\mybullet$) allowing to compose two \emph{ampar}s by writing the root of the second one to a destination of the first one, so by throwing $\ottkw{to}_{\ottstype{\ltimes}}$ to the mix, we can compose an \emph{ampar} with a normal (completed) structure (see the sugar operator \textsc{FillLeaf} ($\triangleleft$) in Section~\ref{ssec:sugar}).

$\ottkw{from}_{\ottstype{\ltimes}}$ is used to convert an \emph{ampar} to a pair, when the right side of the \emph{ampar} is an exponential of the form $[[ᴇ ¹∞ v]]$. Indeed, when the right side has such form, it cannot contains destinations (as destinations always have a finite age), thus it cannot contain holes in its left side either (as holes on the left side are always compensated 1:1 by a destination on the right side). As a result, it is valid to convert an \emph{ampar} to a pair in these circumstances. $\ottkw{from}_{\ottstype{\ltimes}}$ is in particular used to extract a structure from its \emph{ampar} building shell when it is complete (see the sugar operator $\ottkw{from'}_{\ottstype{\ltimes}}$ in Section~\ref{ssec:sugar}).

The remaining term operators $[[⨞]][[()]], [[⨞]][[Inl]], [[⨞]][[Inr]], [[⨞]]\,\expcons{[[m]]}, [[⨞]][[(,)]], [[⨞]](\lamnt{[[x]]}{[[m]]}{[[u]]})$ are all destination-filling primitives. They write a layer of value/constructor to the hole pointed by the destination operand, and return the potential new destinations that are created in the process (or unit if there is none).

\subsection{Syntactic sugar for constructors and commonly used operations}\label{ssec:sugar}

\ottgrammartabular{
\ottsterm\ottafterlastrule
}

\activespaces

\begin{table}[h]
\centering\small
\setlength\tabcolsep{0.4ex}
\begin{tabular}{|lcl|lcl|}
\hline

$[[alloc]]$ & $\triangleq$ & $\begin{array}[t]{l}[[
  { 1 } ⟨ +1 ❟ -1 ⟩
]]\end{array}$ &

$[[t ˢ⨞ t']]$ & $\triangleq$ & $\begin{array}[t]{l}[[
t ⨞· (to⧔ t')
]]\end{array}$ \\\hline

$[[from⧔' t]]$ & $\triangleq$ & $\begin{array}[t]{l}[[
(from⧔ (t map un ⟼ un ; ᴇ ¹∞ () )) case ¹ν⮒
‥‥( st , ex ) ⟼ ex case ¹ν⮒
‥‥‥‥ᴇ ¹∞ un ⟼ un ; st
]]\end{array}$ &

$[[ˢλ x m ⟼ u]]$ & $\triangleq$ & $\begin{array}[t]{l}[[
from⧔' (⮒
‥‥alloc map d ⟼⮒
‥‥‥‥d ⨞ ( λ x m ⟼ u )⮒
)
]]\end{array}$ \\\hline

$[[ˢInl t]]$ & $\triangleq$ & $\begin{array}[t]{l}[[
from⧔' (⮒
‥‥alloc map d ⟼⮒
‥‥‥‥d ⨞ Inl ˢ⨞ t⮒
)
]]\end{array}$ &

$[[ˢInr t]]$ & $\triangleq$ & $\begin{array}[t]{l}[[
from⧔' (⮒
‥‥alloc map d ⟼⮒
‥‥‥‥d ⨞ Inr ˢ⨞ t⮒
)
]]\end{array}$ \\\hline

$[[ˢᴇ m t]]$ & $\triangleq$ & $\begin{array}[t]{l}[[
from⧔' (⮒
‥‥alloc map d ⟼⮒
‥‥‥‥d ⨞ ᴇ m ˢ⨞ t⮒
)
]]\end{array}$ &

$[[ˢ( t1 , t2 )]]$ & $\triangleq$ & $\begin{array}[t]{l}[[
from⧔' (⮒
‥‥alloc map d ⟼⮒
‥‥‥‥(d ⨞ (,)) case ¹ν⮒
‥‥‥‥‥‥( d1 , d2 ) ⟼ d1 ˢ⨞ t1 ; d2 ˢ⨞ t2⮒
)
]]\end{array}$ \\\hline

\end{tabular}
\caption{Desugaring of syntactic sugar forms for terms}
\label{tab:desugaring}
\end{table}

\clearpage

\section{Type system}

\subsection{Syntax for types, modes, and typing contexts}

\ottgrammartabular{
\otttype\ottinterrule
\ottmode\ottinterrule
\ottmul\ottinterrule
\ottage\ottinterrule
\ottctx\ottafterlastrule
}

\subsection{Typing of terms and values}

\ottdefnTyXXval{}
\ottdefnTyXXterm{}

\subsection{Derived typing rules for syntactic sugar forms}

\ottdefnTyXXsterm{}

\section{Evaluation contexts and semantics}

\subsection{Evaluation contexts forms}

\ottgrammartabular{
\ottectx\ottinterrule
\ottectxs\ottafterlastrule
}

\subsection{Typing of evaluation contexts and commands}

\ottdefnTyXXectxs{}
\ottdefnTy{}

\subsection{Small-step semantics}

\ottdefnSem{}

\section{Proof of type safety using Coq proof assistant}

\begin{itemize}
\item Not particularly elegant. Max number of goals observed 232
  (solved by a single call to the \verb|congruence| tactic). When you
  have a computer, brute force is a viable strategy. (in particular,
  no semiring formalisation, it was quicker to do directly)
\item Rules generated by ott, same as in the article (up to some
  notational difference). Contexts are not generated purely by syntax,
  and are interpreted in a semantic domain (finite functions).
\item Reasoning on closed terms avoids almost all complications on
  binder manipulation. Makes proofs tractable.
\item Finite functions: making a custom library was less headache than
  using existing libraries (including \verb|MMap|). Existing libraries
  don't provide some of the tools that we needed, but the most important
  factor ended up being the need for a modicum of dependency between
  key and value. There wasn't really that out there. Backed by actual
  functions for simplicity; cost: equality is complicated.
\item Most of the proofs done by author with very little prior
  experience to Coq.
\item Did proofs in Coq because context manipulations are tricky.
\item Context sum made total by adding an extra invalid \emph{mode}
  (rather than an extra context). It seems to be much simpler this
  way.
\item It might be a good idea to provide statistics on the number of
  lemmas and size of Coq codebase.
\item (possibly) renaming as permutation, inspired by nominal sets,
  make more lemmas don't require a condition (but some lemmas that
  wouldn't in a straight renaming do in exchange).
\item (possibly) methodology: assume a lot of lemmas, prove main
  theorem, prove assumptions, some wrong, fix. A number of wrong lemma
  initially assumed, but replacing them by correct variant was always
  easy to fix in proofs.
\item Axioms that we use and why (in particular setoid equality not
  very natural with ott-generated typing rules).
\item Talk about the use and benefits of Copilot.
\end{itemize}

\section{Implementation of destination calculus using in-place memory mutations}

What needs to be changed (e.g. linear alloc)

\section{Related work}

\section{Conclusion and future work}

\clearpage{}
\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}{}

\end{document}
