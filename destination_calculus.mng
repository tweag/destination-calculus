% -*- latex -*-
\documentclass[10pt]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper,left=0.75cm,right=0.75cm,top=1cm,bottom=1.70cm]{geometry}
\usepackage{lmodern}
\usepackage[dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
  }

\usepackage[backend=biber,citestyle=authoryear,style=alphabetic]{biblatex}
\addbibresource{bibliography.bib}

% For OTT rendering
\usepackage[supertabular]{ottalt}
\inputott{destination_calculus_ott.tex}
\usepackage{ottstyling}

\newcommand{\TODO}[1]{~\textnormal{\textcolor{red}{TODO: #1} } }

\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}

\begin{document}

\title{Destination $\lambda$-calculus}
\author{Thomas \textsc{Bagrel}}
\date{\today}

\maketitle

\section{Term and value syntax}

\ottmetavars

\ottgrammartabular{
\otthdn\ottinterrule
\otthdns\ottinterrule
\ottterm\ottinterrule
\ottval\ottinterrule
%\otteterm\ottafterlastrule
}
\ottgrammartabular{
\ottectx\ottinterrule
\ottectxs\ottafterlastrule
}

\section{Type system}

\ottgrammartabular{
\otttype\ottinterrule
\ottmode\ottinterrule
\ottmul\ottinterrule
\ottage\ottinterrule
\ottctx\ottafterlastrule
}

%\clearpage

\ottdefnTyRXXval{}
\ottdefnTyXXterm{}
\ottdefnTyXXectxs{}
\ottdefnTyXXeterm{}

\clearpage
\section{Small-step semantics}

\ottdefnSemXXeterm{}

\section{Remarks on the Coq proofs}

\begin{itemize}
\item Not particularly elegant. Max number of goals observed 232
  (solved by a single call to the \verb|congruence| tactic). When you
  have a computer, brute force is a viable strategy. (in particular,
  no semiring formalisation, it was quicker to do directly)
\item Rules generated by ott, same as in the article (up to some
  notational difference). Contexts are not generated purely by syntax,
  and are interpreted in a semantic domain (finite functions).
\item Reasoning on closed terms avoids almost all complications on
  binder manipulation. Makes proofs tractable.
\item Finite functions: making a custom library was less headache than
  using existing libraries (including \verb|MMap|). Existing libraries
  don't provide some of the tools that we needed, but the most important
  factor ended up being the need for a modicum of dependency between
  key and value. There wasn't really that out there. Backed by actual
  functions for simplicity; cost: equality is complicated.
\item Most of the proofs done by author with very little prior
  experience to Coq.
\item Did proofs in Coq because context manipulations are tricky.
\item Context sum made total by adding an extra invalid \emph{mode}
  (rather than an extra context). It seems to be much simpler this
  way.
\item It might be a good idea to provide statistics on the number of
  lemmas and size of Coq codebase.
\item (possibly) renaming as permutation, inspired by nominal sets,
  make more lemmas don't require a condition (but some lemmas that
  wouldn't in a straight renaming do in exchange).
\item (possibly) methodology: assume a lot of lemmas, prove main
  theorem, prove assumptions, some wrong, fix. A number of wrong lemma
  initially assumed, but replacing them by correct variant was always
  easy to fix in proofs.
\item Axioms that we use and why (in particular setoid equality not
  very natural with ott-generated typing rules).
\end{itemize}

\end{document}
